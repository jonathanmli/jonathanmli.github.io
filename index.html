<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Jonathan Light</title>
  <meta name="author" content="Jonathan Light">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Montserrat Font -->
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;700&display=swap" rel="stylesheet">
  
  <!-- Stylesheet -->
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="figures/LOGO.png">

</head>
<body>

  <!-- Hamburger / Nav Toggle (appears on smaller screens) -->
  <div class="hamburger" id="navToggle">
    &#9776;
  </div>

  <!-- Fixed Sidebar Navigation -->
  <aside class="sidebar" id="sidebarMenu">
    <!-- Name with rotating last name on a new line -->
    <div class="nav-header">
      <h2>
        Jonathan<br>
        <span class="rotating-lastname">
          <div class="rotating-lastname-inner">
            <div>Li</div>
            <div>Light</div>
            <div>明</div>
            <div>アキラ</div>
            <div>명</div>
          </div>
        </span>
      </h2>
    </div>

    <!-- Social icons directly under name -->
    <div class="nav-social-top">
      <!-- Email Icon -->
      <a href="mailto:jonathan.li.connect@gmail.com" class="social-icon">
        <img src="figures/email_icon.svg" alt="Email" class="icon-style">
      </a>
      <!-- LinkedIn Icon -->
      <a href="https://www.linkedin.com/in/jonathan-m-li/" class="social-icon">
        <img src="figures/linkedin-icon.svg" alt="LinkedIn" class="icon-style">
      </a>
      <!-- GitHub Icon -->
      <a href="https://github.com/jonathanmli" class="social-icon">
        <img src="figures/github-mark-white.svg" alt="GitHub" class="icon-style">
      </a>
      <!-- X Icon -->
      <a href="https://x.com/JonathanMLight" class="social-icon">
        <img src="figures/X_logo_2023.svg" alt="X" class="icon-style">
      </a>
      <!-- Google Scholar Icon -->
      <a href="https://scholar.google.com/citations?user=NjUdt4cAAAAJ&hl=en" class="social-icon">
        <img src="figures/google-scholar-icon.svg" alt="Google Scholar" class="icon-style">
      </a>
    </div>

    <!-- Navigation links -->
    <nav class="nav-links">
      <a href="#intro">Home</a>
      <a href="#education">Education</a>
      <a href="#intern-experience">Intern</a>
      <a href="#publications">Publications</a>
      <a href="#services">Services</a>
      <a href="#teaching">Teaching</a>
      <a href="#awards">Awards</a>
      <a href="#othernotes">Notes</a>
      <a href="#quotes">Quotes</a>
    </nav>

    <!-- CV button in the sidebar -->
    <div class="nav-cv">
      <a href="https://raw.githubusercontent.com/jonathanmli/jonathanmli.github.io/main/pdfs/CV.pdf" target="_blank">
        <button class="custom-button generic-button">CV</button>
      </a>
      <small>(may be slightly outdated)</small>
    </div>
  </aside>

  <!-- Main Content Wrapper -->
  <main class="content">

    <!-- Intro Section -->
    <section id="intro" class="intro-container">
      <!-- Intro text on the left -->
      <div class="intro-text">
        <h1>Welcome!</h1>
        <p>
          I am currently a Ph.D. student at Rensselaer Polytechnic Institute, Troy NY (RPI) and a visiting student at Caltech.
          Broadly speaking, I am interested in the interplay between incentives (<strong>economics</strong>), algorithms (<strong>computer science</strong>), 
          and learning (<strong>statistics</strong>). My research explores the intersection of <strong>planning and reasoning</strong>, <strong>decision making</strong>, and machine learning, with a focus on developing <strong>large language models</strong> that can improve their own capabilities through <strong>self-improvement</strong> and <strong>post-training</strong> adaptations.
        </p>
        <p>
          My current work investigates how foundation models can be leveraged for sequential <strong>decision making</strong>, integrating ideas from <strong>reinforcement learning</strong>, <strong>test-time compute</strong>, and adaptive search techniques. I am particularly interested in how foundation models can enhance autonomous agents’ ability to reason, learn, and generalize in complex environments.
        </p>
        <p>
          I like collaborations! Reach out if you've got a cool problem you'd like to chat about.
        </p>
        <p>
          <em>"Know what you know and know what you do not know. That is true wisdom."</em> <br> -- Confucius
        </p>
        <p>
          In modern terms: know the known knowns, known unknowns, and unknown unknowns. I see this as a guiding principle for research and a crucial challenge in building truly intelligent machines.
        </p>
        <p>
          In my spare time, I enjoy playing and designing board games, reading science fiction, electronic music composition, grand strategy games, fencing, and squash. I find well-designed games to be not only elegant but also a deep source of inspiration for research in <strong>planning and reasoning</strong>.
        </p>
      </div>
    
      <!-- Profile pic on the right -->
      <div class="profile-pic">
        <a href="figures/self.jpg">
          <img src="figures/self.jpg" alt="profile photo">
        </a>
      </div>
    </section>



    <!-- Education Section -->
    <section id="education">
      <h2>Education</h2>

      <div class="education-entry">
        <div class="edu-details">
          <strong>Ph.D.</strong> (Sep 2023 - Present)<br>
          Rensselaer Polytechnic Institute (RPI), Troy, NY, U.S.<br>
          Ph.D. student in Computer Science
        </div>
        <div class="edu-logo">
          <img src="figures/RPI.png" alt="RPI">
        </div>
      </div>

      <div class="education-entry">
        <div class="edu-details">
          <strong>M.S.</strong> (Aug 2021 - Mar 2023)<br>
          University of Chicago, Chicago, IL, U.S.<br>
          M.S. in Financial Mathematics
        </div>
        <div class="edu-logo">
          <img src="figures/uchicago.png" alt="UChicago">
        </div>
      </div>

      <div class="education-entry">
        <div class="edu-details">
          <strong>B.S.</strong> (Aug 2017 - May 2021)<br>
          Reed College, Portland, OR, U.S.<br>
          B.S. in Mathematics and Economics
        </div>
        <div class="edu-logo">
          <img src="figures/reed.png" alt="Reed">
        </div>
      </div>
    </section>

    <!-- Intern Experience Section -->
    <section id="intern-experience">
      <h2>Intern Experience</h2>
      <ul>
        <li>
          <p>
            <strong>May 2024 -- Jan 2025, NEC Laboratories America</strong>, Princeton, NJ<br>
            Research Intern
          </p>
        </li>
      </ul>
    </section>

    <!-- Publications Section -->
    <section id="publications">
      <h2>Publications</h2>

      <!-- 1) Strategist -->
      <div class="publication-card">
        <div class="publication-card-header">
          <img src="figures/strategist.png" alt="strategist">
          <div>
            <p class="paper-title">Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search</p>
            <p>
              <strong>Jonathan Light*</strong>, Min Cai, Weiqin Chen, Guanzhi Wang, Xiusi Chen, Wei Cheng, Yisong Yue, Ziniu Hu<br>
              <em>International Conference on Learning Representations (ICLR), 2025</em><br>
              Covered by <a href="https://docs.google.com/presentation/d/1GmZmoWOa2O92BPrncRcTKa15xvQGhq7g4I4hJSNlC0M/edit#slide=id.g2d35a16f27e_0_24">State of AI Report 2024</a>, published by <a href="https://www.stateof.ai/">Air Street Capital</a>
            </p>
            <div class="pub-buttons">
              <a href="https://github.com/jonathanmli/Avalon-LLM/tree/main/strategist">
                <button class="custom-button generic-button">Code</button>
              </a>
              <a href="https://llm-strategist.github.io/">
                <button class="custom-button generic-button">Website</button>
              </a>
              <a href="https://arxiv.org/pdf/2408.10635">
                <button class="custom-button generic-button">PDF</button>
              </a>
            </div>
          </div>
        </div>
        <div class="card-abstract">
          <p>
            In this paper, we propose a new method STRATEGIST that utilizes LLMs to acquire new skills for playing multi-agent games 
            through a self-improvement process. Our method gathers quality feedback through self-play simulations with Monte Carlo tree search 
            and LLM-based reflection, leading to robust decision-making and better performance in games including the Game of Pure Strategy (GOPS) 
            and The Resistance: Avalon.
          </p>
        </div>
      </div>

      <!-- 2) SFS -->
      <div class="publication-card">
        <div class="publication-card-header">
          <img src="figures/sfs.png" alt="sfs">
          <div>
            <p class="paper-title">Scattered Forest Search: Smarter Code Space Optimization improves LLM Inference Scaling</p>
            <p>
              <strong>Jonathan Light*</strong>, Yue Wu, Yiyou Sun, Wenchao Yu, Yanchi Liu, Xujiang Zhao, Ziniu Hu, Haifeng Chen, Wei Cheng<br>
              <em>International Conference on Learning Representations (ICLR), 2025</em>
            </p>
            <div class="pub-buttons">
              <a href="https://github.com/codespace-optimization/sfs">
                <button class="custom-button generic-button">Code</button>
              </a>
              <a href="https://codespace-optimization.github.io/">
                <button class="custom-button generic-button">Website</button>
              </a>
              <a href="https://arxiv.org/pdf/2411.05010">
                <button class="custom-button generic-button">PDF</button>
              </a>
            </div>
          </div>
        </div>
        <div class="card-abstract">
          <p>
            We propose a novel approach to scaling LLM inference for code generation. By framing code generation as a black-box optimization 
            problem within code space, we introduce Scattered Forest Search to enhance diversity. Experiments show significant performance 
            gains on HumanEval, MBPP, APPS, CodeContests, and Leetcode.
          </p>
        </div>
      </div>

      <!-- 3) PIANIST -->
      <div class="publication-card">
        <div class="publication-card-header">
          <img src="figures/pianist.png" alt="pianist">
          <div>
            <p class="paper-title">PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making</p>
            <p>
              <strong>Jonathan Light</strong>, Sixue Xing, Yuanzhe Liu, Weiqin Chen, Min Cai, Xiusi Chen, Guanzhi Wang, 
              Wei Cheng, Yisong Yue, Ziniu Hu<br>
              <em>Language Gamification Workshop 2024 @ NeurIPS</em>
            </p>
            <div class="pub-buttons">
              <a href="https://arxiv.org/pdf/2411.15998">
                <button class="custom-button generic-button">PDF</button>
              </a>
            </div>
          </div>
        </div>
        <div class="card-abstract">
          <p>
            We propose PIANIST, a framework for decomposing the world model into intuitive components for zero-shot LLM generation 
            in complex multi-agent decision-making tasks. Given only natural language descriptions of the game and input observations, 
            our method can generate a working world model for fast and efficient MCTS simulation.
          </p>
        </div>
      </div>

      <!-- 4) Avalon -->
      <div class="publication-card">
        <div class="publication-card-header">
          <img src="figures/merlin.jpg" alt="merlin">
          <div>
            <p class="paper-title">From Text to Tactic: Evaluating LLMs Playing the Game of Avalon</p>
            <p>
              <strong>Jonathan Light*</strong>, Min Cai, Sheng Shen, Ziniu Hu<br>
              <em>NeurIPS Foundation Models for Decision Making Workshop, 2023</em>
            </p>
            <div class="pub-buttons">
              <a href="https://arxiv.org/pdf/2310.05036.pdf">
                <button class="custom-button generic-button">PDF</button>
              </a>
              <a href="https://avalonbench.github.io/" target="_blank">
                <button class="custom-button generic-button">Website</button>
              </a>
              <a href="https://github.com/jonathanmli/Avalon-LLM" target="_blank">
                <button class="custom-button generic-button">Code</button>
              </a>
            </div>
          </div>
        </div>
        <div class="card-abstract">
          <p>
            In this paper, we explore the potential of LLM Agents in playing the strategic social deduction game, Resistance Avalon. 
            We introduce AVALONBENCH, a comprehensive game environment for multi-agent LLMs. Our evaluations highlight 
            a capability gap between current LLM Agents and well-engineered baseline bots, revealing opportunities for improvement.
          </p>
        </div>
      </div>

      <!-- 5) Dataset Distillation for Offline RL -->
      <div class="publication-card">
        <div class="publication-card-header">
          <img src="figures/dataset_distill_rl.png" alt="dataset-distill-rl">
          <div>
            <p class="paper-title">Dataset Distillation for Offline Reinforcement Learning</p>
            <p>
              <strong>Jonathan Light*</strong>, Yuanzhe Liu, Ziniu Hu<br>
              <em>ICML Data-centric Machine Learning Research Workshop, 2024</em>
            </p>
            <div class="pub-buttons">
              <a href="https://arxiv.org/pdf/2407.20299" target="_blank">
                <button class="custom-button generic-button">PDF</button>
              </a>
              <a href="https://datasetdistillation4rl.github.io/" target="_blank">
                <button class="custom-button generic-button">Website</button>
              </a>
              <a href="https://github.com/ggflow123/DDRL" target="_blank">
                <button class="custom-button generic-button">Code</button>
              </a>
            </div>
          </div>
        </div>
        <div class="card-abstract">
          <p>
            Offline reinforcement learning often requires a quality dataset for training. We propose data distillation 
            to synthesize a smaller, higher-quality dataset for training a better policy. Our experiments show 
            that models trained on the distilled dataset achieve comparable performance to those trained on the full dataset.
          </p>
        </div>
      </div>

    </section>

    <!-- Services Section -->
    <section id="services">
      <h2>Academic Services</h2>
      <ul>
        <li>Journal/Conference Reviewer: ICLR2025</li>
      </ul>
    </section>

    <!-- Teaching Section -->
    <section id="teaching">
      <h2>Teaching</h2>
      <ul>
        <li>Teaching Assistant, AI and Blockchain, Dacheng Xiu. Booth EMBA, 2023 Summer</li>
        <li>Teaching Assistant, Options Pricing, Roger Lee. UChicago PSD, 2023 Spring</li>
        <li>Teaching Assistant, Bayesian Statistical Inference and ML, Gordan Ritter. UChicago PSD, 2023 Spring</li>
        <li>Teaching Assistant, Decoding Fintech, Dacheng Xiu. Booth, 2023 Winter</li>
        <li>Teaching Assistant, Mathematical Statistics, Jonathan Wells. Reed College, 2021 Spring</li>
        <li>Teaching Assistant, Probability Theory, Jonathan Wells. Reed College, 2020 Fall</li>
        <li>Teaching Assistant, Macroeconomics, Zhe (Jasmine) Jiang. Reed College, 2020 Fall</li>
        <li>Teaching Assistant, Econometrics, Fellipe Carrera. Reed College, 2020 Fall</li>
        <li>Teaching Assistant, Introduction to Analysis, David Krumm. Reed College, 2019 Fall</li>
      </ul>
    </section>

    <!-- Awards Section -->
    <section id="awards">
      <h2>Honors and Awards</h2>
      <ul>
        <li>Phi Beta Kappa, 2021</li>
        <li>Reed Commendation for Excellence in Scholarship, 2018, 2019, 2020, 2021</li>
        <li>Reed Science Research Fellow, 2020</li>
        <li>Reed Financial Services Fellow, 2019</li>
      </ul>
    </section>

    <!-- Other Notes Section -->
    <section id="othernotes">
      <h2>Other Notes</h2>
      <p>
        I go by either Jonathan Li or Jonathan Light. I usually use Light in publications because (1) Li is a very common last name. Without exception, every institution I've been to has had at least one other Jonathan Li. (2) Light is the semantic translation of my Chinese given name. (3) Light nearly preserves the lexigraphic ordering of Li. 
      </p>
      <p>
        I've also considered using 'Plum' (the semantic translation of my last name), but it doesn't have the same ring to it, nor does it preserve the lexigraphic ordering of Li.
        Generally I find semantic translations to be more faithful to the original meaning, as convenient as pinyin is for romanization.
      </p>
    </section>

    <!-- Quotes Section -->
    <section id="quotes">
      <h2>Other Quotes and Historical Tidbits</h2>
      <p>
        I find quotes and historical tidbits to be a great source of inspiration and very fascinating. Here are some of my favorites that I've collected over the years.
      </p>
      <ul>
        <li>
          “Ask yourself whether you are happy, and you cease to be so” — John Stuart Mill. Says something about opportunity cost and the paradox of choice
        </li>
        <li>
          “The best is the enemy of the good” — Voltaire. This principle is used so often in optimization, approximation, and machine learning
        </li>
        <li>
          “Stay hungry. Stay foolish” — Steve Jobs. It's good to be foolish. Then you can ask any question you want
        </li>
      </ul>
    </section>

    <!-- Footer or Final Note -->
    <footer>
      <p>
        <a href="https://jonbarron.info/">Website Template Source</a>
      </p>

      <!-- Add the ClustrMaps globe script -->
      <div style="text-align:center; margin-top:20px;">
        <script type="text/javascript" id="clstr_globe" 
                src="//clustrmaps.com/globe.js?d=PeHeHzW3ltrX6TSgOTg0FnVvurZigdczh36CUtajiD8">
        </script>
      </div>
    </footer>
  </main>

  <!-- Toggle Sidebar Script -->
  <script>
    const navToggle = document.getElementById('navToggle');
    const sidebarMenu = document.getElementById('sidebarMenu');

    // On smaller screens, toggle the sidebar open/close
    navToggle.addEventListener('click', () => {
      sidebarMenu.classList.toggle('open');
    });
  </script>
</body>
</html>
